{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7cacc0cf-4d0c-4857-9904-386a90c06598",
   "metadata": {},
   "source": [
    " performance metrix\n",
    "\n",
    "  [Tp ,Fp]          Tp =truepositive , Fp=Falsepositive\n",
    "  [Fn ,Tn]    \n",
    "\n",
    "  ->Accuracy=  Tp+Tn/(Tp+Tn+Fp+Fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10a507ac-f32e-42e5-a11f-6d3a976d3df3",
   "metadata": {},
   "source": [
    "If the data is imbalanced ,\n",
    "for example , 900 zeros and 100 ones \n",
    "then we will use precision\n",
    "\n",
    "precision=  Tp/Tp+Fp\n",
    "\n",
    "recall=Tp/Tp+Fn\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3f458cc-d8c1-49ba-a200-bbcbe4d7b9e6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "77a41754-d090-43b2-ad54-854c6541f269",
   "metadata": {},
   "source": [
    "Precision: Of all the predicted positives, how many were actually correct?\n",
    "\n",
    "Precision\n",
    "=\n",
    "True¬†Positives\n",
    "True¬†Positives¬†+¬†False¬†Positives\n",
    "Precision= \n",
    "True¬†Positives¬†+¬†False¬†Positives\n",
    "True¬†Positives\n",
    "‚Äã\n",
    " \n",
    "Recall: Of all actual positives, how many did we correctly find?\n",
    "\n",
    "Recall\n",
    "=\n",
    "True¬†Positives\n",
    "True¬†Positives¬†+¬†False¬†Negatives\n",
    "Recall= \n",
    "True¬†Positives¬†+¬†False¬†Negatives\n",
    "True¬†Positives\n",
    "‚Äã\n",
    " \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31b0a31c-2607-4b96-9359-212e37be78e6",
   "metadata": {},
   "source": [
    "üéØ When to Use Precision\n",
    "Use precision when:\n",
    "\n",
    "‚úÖ False positives are costly\n",
    "\n",
    "üì° When to Use Recall\n",
    "Use recall when:\n",
    "\n",
    "‚úÖ False negatives are costly"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c392ff8-bba6-4d03-b689-3fb55630d36e",
   "metadata": {},
   "source": [
    "‚öñÔ∏è Use Both: The F1 Score\n",
    "If you want a balance between precision and recall, especially in imbalanced datasets;\n",
    "\n",
    "F=\n",
    "2\n",
    "√ó\n",
    "Precision\n",
    "√ó\n",
    "Recall\n",
    "Precision¬†+¬†Recall\n",
    "F1=2√ó \n",
    "Precision¬†+¬†Recall\n",
    "Precision√óRecall\n",
    "‚Äã\n",
    "\n",
    "\n",
    "But there is problem, the actual formula contains Beta , which changes from condition to condition, so this Topic is unclear to me.I have to study again this one only."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30452c91-588d-40ce-bc07-ce137821f59e",
   "metadata": {},
   "source": [
    "# RUC AND AUC \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "393dcb21-7620-4c13-a235-aed88d3e5213",
   "metadata": {},
   "source": [
    "Confusion matrix ham tabhi banate hen jab 0 1 pe baat ajae , jab mtlb ham MSE , MAE , RMSE use na kr sken , "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e15242b8-d749-44e2-bc0a-9668c016c183",
   "metadata": {},
   "source": [
    "ROC Curve Plot: Shows how well your model discriminates between classes. A curve closer to the top-left corner indicates a better model.\n",
    "\n",
    "AUC Score: Tells you how good the model is overall. A higher AUC means the model has better predictive powe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c292c75-61eb-4b53-b1a1-dd9493c4d41b",
   "metadata": {},
   "source": [
    "Problem Type\tBest Metric(s)\tWhen to Use?\n",
    "Binary Classification\tPrecision, Recall, F1-score, AUC-ROC\tPrecision when false positives are costly, Recall when false negatives are costly.\n",
    "Multi-class Classification\tAccuracy, F1-score, Confusion Matrix\tAccuracy for balanced data, F1-score for imbalanced data.\n",
    "Regression\tMAE, MSE, RMSE, R¬≤\tRMSE for penalizing large errors, MAE for easy interpretation, R¬≤ for model explanation.\n",
    "Clustering\tSilhouette Score, Davies-Bouldin Index, ARI\tSilhouette Score for compact clusters, ARI for comparing clustering results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f04968fb-25a8-4d57-bfa8-562b8b8324a6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
